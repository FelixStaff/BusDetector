{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "class BusDataset(Dataset):\n",
    "\n",
    "    def __init__(self, class_csv, image_path,max_data_loaded=100):\n",
    "        self.bus_df = pd.read_csv(class_csv)\n",
    "        # if the labels != bus, make it 0, else make it 1\n",
    "        self.labels = []\n",
    "        self.image_path = image_path\n",
    "        self.image = []\n",
    "        self.Image_len = 0\n",
    "        self.Transform = transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Resize((256, 256)),\n",
    "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        for file in os.listdir(self.image_path):\n",
    "            if file.endswith('.jpg'):\n",
    "                # take the tensor of the image\n",
    "                img = self.Transform(plt.imread(os.path.join(self.image_path, file)))\n",
    "                self.image.append(img)\n",
    "                self.Image_len += 1\n",
    "                # search for the LabelName but without .jpg\n",
    "                label = self.bus_df.loc[self.bus_df['ImageID'] == file[:-4], 'LabelName'].values[0]\n",
    "                self.labels.append(1 if label == 'Bus' else 0)\n",
    "                if len(label) == 0:\n",
    "                    self.labels.append(0)\n",
    "            if self.Image_len == max_data_loaded:\n",
    "                break\n",
    "        print (\"Label Size: \", len(self.labels))\n",
    "        print (\"Image Size: \", len(self.image))\n",
    "        self.image = torch.stack(self.image)\n",
    "        self.Image_len = len(self.image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Image_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felipe de Jesus\\miniconda3\\envs\\MLearn\\lib\\site-packages\\torchvision\\transforms\\functional.py:150: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:178.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Size:  8000\n",
      "Image Size:  8000\n"
     ]
    }
   ],
   "source": [
    "dataset = BusDataset('archive/df.csv', 'archive/images/images/', max_data_loaded=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "train_loader = DataLoader(dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Downsample Block\n",
    "def downsample_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network as a Convolutional Neural Network\n",
    "class BusDetector(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(BusDetector, self).__init__()\n",
    "        # Input [3, 256, 256]\n",
    "        self.conv1 = downsample_block(3, 64) # [3, 256, 256] -> [64, 128, 128]\n",
    "        self.MaxPool1 = nn.MaxPool2d(kernel_size=2, stride=2) # [64, 128, 128] -> [64, 64, 64]\n",
    "        self.conv2 = downsample_block(64, 128) # [64, 64, 64] -> [128, 32, 32]\n",
    "        self.MaxPool2 = nn.MaxPool2d(kernel_size=2, stride=2) # [128, 32, 32] -> [128, 16, 16]\n",
    "        self.conv3 = downsample_block(128, 256) # [128, 16, 16] -> [256, 8, 8]\n",
    "        self.MaxPool3 = nn.MaxPool2d(kernel_size=2, stride=2) # [256, 8, 8] -> [256, 4, 4]\n",
    "        self.conv4 = downsample_block(256, 512) # [256, 4, 4] -> [512, 2, 2]\n",
    "        self.MaxPool4 = nn.MaxPool2d(kernel_size=2, stride=2) # [512, 2, 2] -> [512, 1, 1]\n",
    "        # Fully Connected Layer and Flatten\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.MaxPool1(self.conv1(x)) # [3, 256, 256] -> [64, 128, 128] -> [64, 64, 64]\n",
    "        out = self.MaxPool2(self.conv2(out)) # [64, 64, 64] -> [128, 32, 32] -> [128, 16, 16]\n",
    "        out = self.MaxPool3(self.conv3(out)) # [128, 16, 16] -> [256, 8, 8] -> [256, 4, 4]\n",
    "        out = self.MaxPool4(self.conv4(out)) # [256, 4, 4] -> [512, 2, 2] -> [512, 1, 1]\n",
    "        out = self.Flatten(out) # [512, 1, 1] -> [512]\n",
    "        out = F.relu(self.fc1(out)) # [512] -> [128]\n",
    "        out = torch.sigmoid(self.fc2(out)) # [128] -> [1]\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BusD = BusDetector()\n",
    "#print(BusD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and the optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(BusD.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  Loss:  10.141899704933167\n",
      "Epoch:  1  Loss:  7.999439537525177\n",
      "Epoch:  2  Loss:  6.418636292219162\n",
      "Epoch:  3  Loss:  5.27546226978302\n",
      "Epoch:  4  Loss:  3.7931689620018005\n",
      "Epoch:  5  Loss:  2.237104669213295\n",
      "Epoch:  6  Loss:  1.1597260981798172\n",
      "Epoch:  7  Loss:  0.44545393623411655\n",
      "Epoch:  8  Loss:  0.17925817845389247\n",
      "Epoch:  9  Loss:  0.10648090043105185\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = BusD(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #save the loss\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(\"Epoch: \", epoch, \" Loss: \", epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(BusD.state_dict(), 'BusDetector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('MLearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9178488e902897ccede7ccf72145ea4bf1db4863c1b153f9ec9b532ffe6212a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
